---
title: "Flow Concepts"
tbl-colwidths: [30,70]
---

The primary interface for defining a workflow in Flow is a `FlowJob`. A `FlowJob` defines the log directory, tasks, models, and other options that make up the job. When Inspect Flow processes the `FlowJob`, it resolves the configuration into a list of evaluation tasks to be run. These tasks are provided to Inspect's `eval_set()` function along with any additional configuration, and Inspect executes the tasks.

Inspect Flow mirrors Inspect AI's object model with corresponding Flow types:

-   **`FlowJob`** — The top-level job definition. Contains a list of tasks and job settings. Under the hood it translates to an Inspect AI [Eval Set](https://inspect.aisi.org.uk/eval-sets.html).
-   **`FlowTask`** — Configuration for a single evaluation task. Maps to Inspect AI [Task](https://inspect.aisi.org.uk/tasks.html) parameters.
-   **`FlowModel`** — Model configuration including API settings and generation settings. Maps to Inspect AI [Model](https://inspect.aisi.org.uk/models.html).
-   **`FlowSolver`** and **`FlowAgent`** — Solver and agent chain configuration. Map to Inspect AI [Solver](https://inspect.aisi.org.uk/solvers.html) and [Agent](https://inspect.aisi.org.uk/agents.html).
-   **`FlowScorer`** — Configuration for a Scorer. Maps to Inspect AI [Scorer](https://inspect.aisi.org.uk/scorer.html).
-   **`FlowOptions`** — Runtime execution options. Maps to Inspect AI [eval_set()](https://inspect.aisi.org.uk/reference/inspect_ai.html#eval_set) parameters.
-   **`FlowDefaults`** — System for setting default values across tasks, models, solvers, and agents.
-   **`FlowDependencies`** — Configuration for evaluation dependencies to install.

## Config Files

Flow configuration files are Python files where the last expression is either:

- A `FlowJob` object, or
- A function that returns a `FlowJob` object

Since config files are standard Python code, you can use all Python features including variables, loops, comprehensions, imports, and comments. Flow configs are just Python!

## Basic Example

In [Welcome - Basic Example](index.qmd#basic-example), we showed a simple `FlowJob`. Let's break down what's happening:

``` {.python filename="config.py"}
{{< include ../examples/first_config.py >}}
```

1.  Specify the directory for storing logs

2.  List evaluation tasks to run

3.  Specify task from registry by name

4.  Specify model to evaluate by name

To run the task, run the following command in your shell.

``` bash
flow run config.py
```

![Progress bar in terminal](images/first_config_progress_terminal.png)

**What happens when you run this?**

1.  Flow creates an isolated virtual environment
2.  Installs `inspect-evals` and `openai` (auto-detected)
3.  Loads the `gpqa_diamond` task from the `inspect_evals` registry
4.  Runs the evaluation with GPT-5
5.  Stores results in `logs/`

## Jobs

`FlowJob` is the primary interface for defining Flow workflows. All Flow operations—including [parameter sweeps and matrix expansions](matrix.qmd)—ultimately produce a list of tasks that `FlowJob` executes.

**Required fields:**

| Field | Description |
|------------------|--------------------------------|
| `log_dir` | Output path for logging results. Supports S3 paths (e.g., `s3://bucket/path`) |

**Optional fields:**

| Field | Description | Default |
|------------------|--------------------------------|----------------------|
| `tasks` | List of tasks to run (`FlowTask` objects or strings) | `None` |
| `includes` | List of other flow configs to include (paths as strings). Relative paths resolved relative to config file (CLI) or `base_dir` arg (API). Additionally, any `_flow.py` files in the same directory or parent directories are automatically included | `None` |
| `log_dir_create_unique` | If `True`, append numeric suffix to `log_dir` if it exists. If `False`, use existing directory (must only contain logs from tasks in the job or have `options.log_dir_allow_dirty=True`) | `False` |
| `python_version` | Python version for the isolated virtual environment (e.g., `"3.11"`) | Same as current environment |
| `dependencies` | `FlowDependencies` object configuring package installation. Controls dependency file detection, additional packages, and auto-detection behavior | Auto-detect from `pyproject.toml` or `requirements.txt`, and config object names |
| `env` | Environment variables to set when running tasks | `None` |
| `options` | Runtime options passed to `eval_set` (see `FlowOptions` reference) | `None` |
| `defaults` | Default values applied across tasks, models, solvers, and agents (see [Defaults](defaults.qmd) and `FlowDefaults` reference) | `None` |
| `flow_metadata` | Metadata stored in the flow config (not passed to Inspect AI, see [flow_metadata](advanced.qmd#flow_metadata-flow-only-metadata)) | `None` |

## Tasks

`FlowTask` defines the configuration for a single evaluation. Each `FlowTask` maps to an Inspect AI [Task](https://inspect.aisi.org.uk/tasks.html) and accepts the same parameters—including the model to evaluate, solver chain, generation config, sandbox environment, and dataset filters.

### Specification

In the example above, we used a registry name (`"inspect_evals/gpqa_diamond"`). Flow supports multiple ways to reference tasks:

**Registry Name**

``` python
# Tasks from installed packages
FlowTask(
    name="inspect_evals/gpqa_diamond",
    model="openai/gpt-5"
)
```

**File Path**

``` python
# Auto-discovers `@task` decorated functions in the specified file and creates a task for each of them
FlowTask(
    name="./my_task.py",
    model="openai/gpt-5"
)
```

**File with Function**

``` python
# Explicitly selects a specific function from the file
FlowTask(
    name="./my_task.py@custom_eval",
    model="openai/gpt-5"
)
```

### Configuration

`FlowTask` accepts parameters that map to Inspect AI [Task](https://inspect.aisi.org.uk/tasks.html) fields. The examples below show commonly used fields; see the `FlowTask` reference documentation for the complete list of available parameters.

``` python
FlowTask(
    name="inspect_evals/mmlu_0_shot",   # <1>
    model="openai/gpt-5",               # <2>
    epochs=3,                           # <3>
    config=GenerateConfig(              # <4>
        temperature=0.7,                # <4>
        max_tokens=1000,                # <4>
    ),                                  # <4>
    solver="chain_of_thought",          # <5>
    args={"subject": "physics"},        # <6>
    sandbox="docker",                   # <7>
    sample_id=[0, 1, 2],                # <8>
)
```

1.  **Task name** — Maps to Inspect AI `Task.name`. Can be a registry name (`"inspect_evals/mmlu"`), file path (`"./task.py"`), or file with function (`"./task.py@eval_fn"`).

2.  **Model** — Maps to Inspect AI `Task.model`. Optional model for this task. If not specified, uses the model from `INSPECT_EVAL_MODEL` environment variable. Can be a string (`"openai/gpt-5"`) or a `FlowModel` object for advanced configuration.

3.  **Epochs** — Maps to Inspect AI `Task.epochs`. Number of times to repeat evaluation over the dataset samples. Can be an integer (`epochs=3`) or a `FlowEpochs` object to specify custom reducer functions (`FlowEpochs(epochs=3, reducer="median")`). By default, scores are combined using the `"mean"` reducer across epochs.

4.  **Generation config** — Maps to Inspect AI `Task.config` (`GenerateConfig`). Model generation parameters like `temperature`, `max_tokens`, `top_p`, `reasoning_effort`, etc. These settings override config on `FlowJob.config` but are overridden by settings on `FlowModel.config`.

5.  **Solver chain** — Maps to Inspect AI `Task.solver`. The algorithm(s) for solving the task. Can be a string (`"chain_of_thought"`), `FlowSolver` object, `FlowAgent` object, or a list of solvers for chaining. Defaults to `generate()` if not specified.

6.  **Task arguments** — Maps to task function parameters. Dictionary of arguments passed to the task constructor or `@task` decorated function. Enables parameterization of tasks (e.g., selecting dataset subsets, configuring difficulty levels).

7.  **Sandbox environment** — Maps to Inspect AI `Task.sandbox`. Can be a string (`"docker"`, `"local"`), a tuple with additional config, or a `SandboxEnvironmentType` object.

8.  **Sample selection** — Evaluate specific samples from the dataset. Accepts a single ID (`sample_id=0`), list of IDs (`sample_id=[0, 1, 2]`), or list of string IDs.

## Models

When specifying a task, you can provide the model for the task as either a string with a model name or as a `FlowModel`. When using the simple string, the default values for that model will be used. For example:

``` python
FlowTask(name="task", model="openai/gpt-5")
```

Using `FlowModel` allows you to specify additional parameters for the model (e.g. `GenerateConfig`). Use `FlowModel` when you need to set custom `GenerateConfig`, API endpoints, custom API keys for a specific model, or perform other custom configuration. For example:

``` python
FlowTask(
    name="task",
    model=FlowModel(
        name="openai/gpt-5",
        config=GenerateConfig(
            reasoning_effort="medium",
            max_connections=10,
        ),
        base_url="https://custom-endpoint.com",
        api_key="${CUSTOM_API_KEY}",
    )
)
```

### Model Roles

For agent evaluations with multiple model roles, use `model_roles` to specify which model to use for each role. For example:

``` python
# For agent evaluations with multiple roles
FlowTask(
    name="multi_agent_task",
    model_roles={
        "assistant": "openai/gpt-5",
        "critic": "anthropic/claude-3-5-sonnet",
    }
)
```